{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_list_of_image_names(abs_path, extension):\n",
    "    list_of_image_names = glob(os.path.join(abs_path, '*'+extension))\n",
    "    return list_of_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dateset(list_of_image_names, square=False, newsize=None, color=False):\n",
    "    dataset = []\n",
    "    for img_name in list_of_image_names:\n",
    "        if color:\n",
    "            img = cv2.imread(img_name,1) #array 720x1280 rgb\n",
    "        else:\n",
    "            img = cv2.imread(img_name,0) #array 720x1280 grayscale\n",
    "        if (img is None):\n",
    "            print(img_name,'non eksiste')\n",
    "        else:\n",
    "            if square:\n",
    "                img = img[:,280:1000] #subentendendo que a imagem ori eh 720x1280\n",
    "            if newsize:\n",
    "                img = cv2.resize(img, newsize) \n",
    "            dataset.append(img)\n",
    "    #print(type(img))\n",
    "#     print(len(dataset))\n",
    "#     print(type(dataset))\n",
    "    dataset = np.stack(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def normalize(data):\n",
    "    #mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] #pytorch\n",
    "    #mean=[ 103.939, 116.779, 123.68 ], std=\n",
    "    mean = data.mean(axis=(0,1,2)).astype(np.float32)\n",
    "    stddev = data.std(axis=(0,1,2)).astype(np.float32)\n",
    "    data = data.astype(np.float32) - mean\n",
    "    data /= stddev\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate(ds, labels=None):\n",
    "    p = np.random.permutation(ds.shape[0])\n",
    "    ds = ds[p]\n",
    "    if (labels is not None):\n",
    "        labels = labels[p]\n",
    "        return ds, labels\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_targets(n):\n",
    "    return tuple([np.identity(n)[i,:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/henriquegoncalves/Documents/UFRJ/PF2/Images/imagens_v1/'\n",
    "cl_names = ['dano', 'variacao', 'duto']\n",
    "cl_paths = {}\n",
    "\n",
    "for i in range(len(cl_names)):\n",
    "    cl_paths[cl_names[i]] = gen_list_of_image_names(os.path.join(path,cl_names[i]),'.jpg')\n",
    "\n",
    "#print(cl_paths['dano'][324])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando quais videos são treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_name = 'HD_C_pl0138_VOL006'\n",
    "valid_video_name = 'HD_C_pl0138_VOL007'\n",
    "te_paths = {}\n",
    "tr_paths = {}\n",
    "v_paths = {}\n",
    "\n",
    "for i in range(len(cl_names)):\n",
    "    te_paths[cl_names[i]] = [path for path in cl_paths[cl_names[i]] if test_video_name in path]\n",
    "    v_paths[cl_names[i]] = [path for path in cl_paths[cl_names[i]] if valid_video_name in path]\n",
    "\n",
    "    tr_paths[cl_names[i]] = [path for path in cl_paths[cl_names[i]] if test_video_name not in path]\n",
    "    tr_paths[cl_names[i]] = [path for path in tr_paths[cl_names[i]] if valid_video_name not in path]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "v_paths['variacao'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerar os arquivos de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "te_data = {}\n",
    "tr_data = {}\n",
    "v_data = {}\n",
    "\n",
    "for i in range(len(cl_names)):\n",
    "    te_data[cl_names[i]] = gen_dateset(te_paths[cl_names[i]],square=True, newsize=(224,224), color=True)\n",
    "    tr_data[cl_names[i]] = gen_dateset(tr_paths[cl_names[i]],square=True, newsize=(224,224), color=True)\n",
    "    v_data[cl_names[i]] = gen_dateset(v_paths[cl_names[i]],square=True, newsize=(224,224), color=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_data['variacao'].shape[0],tr_data['duto'].shape[0],tr_data['dano'].shape[0])\n",
    "print(te_data['variacao'].shape[0],te_data['duto'].shape[0],te_data['dano'].shape[0])\n",
    "print(v_data['variacao'].shape[0],v_data['duto'].shape[0],v_data['dano'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancear as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_list = []\n",
    "te_list = []\n",
    "v_list = []\n",
    "\n",
    "for cl_name in cl_names:\n",
    "    tr_list.append(tr_data[cl_name].shape[0])\n",
    "    te_list.append(te_data[cl_name].shape[0])\n",
    "    v_list.append(v_data[cl_name].shape[0])\n",
    "\n",
    "tr_m = min(tr_list)\n",
    "te_m = min(te_list)\n",
    "v_m = min(v_list)\n",
    "    \n",
    "for cl_name in cl_names:\n",
    "    tr_data[cl_name] = permutate(tr_data[cl_name])\n",
    "    te_data[cl_name] = permutate(te_data[cl_name])\n",
    "    v_data[cl_name] = permutate(v_data[cl_name])\n",
    "    \n",
    "for cl_name in cl_names:\n",
    "    tr_data[cl_name] = tr_data[cl_name][:tr_m]\n",
    "    v_data[cl_name] = v_data[cl_name][:v_m]\n",
    "    te_data[cl_name] = te_data[cl_name][:te_m]\n",
    "\n",
    "    \n",
    "    \n",
    "# tr_m = min(tr_cl_data.shape[0], tr_ncl_data.shape[0])\n",
    "# te_m = min(te_cl_data.shape[0], te_ncl_data.shape[0])\n",
    "# v_m = min(v_cl_data.shape[0], v_ncl_data.shape[0])\n",
    "\n",
    "# tr_cl_data = permutate(tr_cl_data)\n",
    "# te_cl_data = permutate(te_cl_data)\n",
    "# v_cl_data = permutate(v_cl_data)\n",
    "# tr_ncl_data = permutate(tr_ncl_data)\n",
    "# te_ncl_data = permutate(te_ncl_data)\n",
    "# v_ncl_data = permutate(v_ncl_data)\n",
    "\n",
    "# tr_cl_data = tr_cl_data[:tr_m]\n",
    "# te_cl_data = te_cl_data[:te_m]\n",
    "# v_cl_data = v_cl_data[:v_m]\n",
    "# tr_ncl_data = tr_ncl_data[:tr_m]\n",
    "# te_ncl_data = te_ncl_data[:te_m]\n",
    "# v_ncl_data = v_ncl_data[:v_m]\n",
    "\n",
    "# print(tr_cl_data.shape, tr_ncl_data.shape, te_cl_data.shape, te_ncl_data.shape, v_cl_data.shape, v_ncl_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([te_data[i].shape[0] for i in cl_names])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "index = 663\n",
    "\n",
    "# fig, axarr = plt.subplots(1,2, figsize=(10,3))\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(tr_data['duto'][index,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(cl_names)\n",
    "targets = gen_targets(n)\n",
    "\n",
    "X_tr = np.concatenate(tuple([tr_data[cl_name] for cl_name in cl_names]))\n",
    "Y_tr = np.concatenate(tuple([np.tile(targets[i],(tr_m,1)) for i in range(n)]))\n",
    "\n",
    "X_v = np.concatenate(tuple([v_data[cl_name] for cl_name in cl_names]))\n",
    "Y_v = np.concatenate(tuple([np.tile(targets[i],(v_m,1)) for i in range(n)]))\n",
    "\n",
    "X_te = np.concatenate(tuple([te_data[cl_name] for cl_name in cl_names]))\n",
    "Y_te = np.concatenate(tuple([np.tile(targets[i],(te_m,1)) for i in range(n)]))\n",
    "\n",
    "\n",
    "# X_tr = np.concatenate((tr_cl_data, tr_ncl_data))\n",
    "# Y_tr = np.concatenate((np.ones((tr_m,1)),np.zeros((tr_m,1))))\n",
    "\n",
    "# X_te = np.concatenate((te_cl_data, te_ncl_data))\n",
    "# Y_te = np.concatenate((np.ones((te_m,1)),np.zeros((te_m,1))))\n",
    "\n",
    "# X_v = np.concatenate((v_cl_data, v_ncl_data))\n",
    "# Y_v = np.concatenate((np.ones((v_m,1)),np.zeros((v_m,1))))\n",
    "\n",
    "X_tr, Y_tr = permutate(X_tr, Y_tr)\n",
    "X_v, Y_v = permutate(X_v, Y_v)\n",
    "X_te, Y_te = permutate(X_te, Y_te)\n",
    "\n",
    "classes = [cl_name.encode() for cl_name in cl_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgroup = X_tr\n",
    "ygroup = Y_tr\n",
    "\n",
    "def interactive_print(index):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(xgroup[index,:,:,:])\n",
    "    print('This image is of class:',classes[np.argmax(ygroup[index,:])].decode())\n",
    "print(len(ygroup))\n",
    "interact(interactive_print, index = (0,len(xgroup)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "index = 11\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(X_tr[index,:,:,:])\n",
    "print('This image is of class:',classes[int(Y_tr[index,0])].decode())\n",
    "print('len:',len(Y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../datasets/'\n",
    "filename = 'softmaxVaDaDu_224color.h5'\n",
    "f = os.path.join(path, filename)\n",
    "\n",
    "h5f = h5py.File(f, 'w')\n",
    "h5f.create_dataset('X_tr', data=X_tr)\n",
    "h5f.create_dataset('Y_tr', data=Y_tr)\n",
    "h5f.create_dataset('X_v', data=X_v)\n",
    "h5f.create_dataset('Y_v', data=Y_v)\n",
    "h5f.create_dataset('X_te', data=X_te)\n",
    "h5f.create_dataset('Y_te', data=Y_te)\n",
    "h5f.create_dataset('classes', data=classes)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "\n",
    "img_path = ['cat.jpg']\n",
    "x = gen_dateset(img_path, color=True, newsize=(224, 224))\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img = cv2.imread('cat.jpg',1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "nc_data = gen_dateset(nc,square=True, newsize=(224,224), color=True)\n",
    "cl_data = gen_dateset(cl,square=True, newsize=(224,224), color=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, axarr = plt.subplots(1,2, figsize=(10,14))\n",
    "axarr[0].imshow(nc_data[0,:,:,:])\n",
    "axarr[1].imshow(cl_data[0,:,:,:])\n",
    "nc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nc_data = nc_data.astype(np.float32) - nc_data.mean(axis=(0,1,2)).astype(np.float32)\n",
    "nc_data = nc_data.astype(np.float32) / nc_data.std(axis=(0,1,2)).astype(np.float32)\n",
    "\n",
    "cl_data = cl_data.astype(np.float32) - cl_data.mean(axis=(0,1,2)).astype(np.float32)\n",
    "cl_data = cl_data.astype(np.float32) / cl_data.std(axis=(0,1,2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "path = './'\n",
    "filename = 'teste1.h5'\n",
    "f = os.path.join(path, filename)\n",
    "\n",
    "h5f = h5py.File(f, 'w')\n",
    "h5f.create_dataset('duto', data=duct_data)\n",
    "h5f.create_dataset('planta', data=plant_data)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = './'\n",
    "filename = 'teste1.h5'\n",
    "f = os.path.join(path, filename)\n",
    "\n",
    "with h5py.File(f, 'r') as hf:\n",
    "    d = hf['duto'][:]\n",
    "    p = hf['planta'][:]\n",
    "\n",
    "print(p.shape)\n",
    "print(d.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = './'\n",
    "filename = 'teste1.h5'\n",
    "f = os.path.join(path, filename)\n",
    "\n",
    "with h5py.File(f, 'r') as hf:\n",
    "    h = hf\n",
    "h['duto'][:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m = min(nc_data.shape[0], cl_data.shape[0])\n",
    "t_len = int(0.6*2*m)\n",
    "v_len = int(0.2*2*m)\n",
    "\n",
    "pc = np.random.permutation(m)\n",
    "pn = np.random.permutation(m)\n",
    "\n",
    "cl_data = cl_data[pc] #embaralha antes de separar\n",
    "nc_data = nc_data[pn]\n",
    "\n",
    "cl_data = cl_data[:m]\n",
    "nc_data = nc_data[:m]\n",
    "assert(cl_data.shape == nc_data.shape)\n",
    "\n",
    "X = np.concatenate((cl_data, nc_data))\n",
    "Y = np.concatenate((np.ones((m,1)),np.zeros((m,1))))\n",
    "\n",
    "X_p = X[perm]\n",
    "Y_p = Y[perm]\n",
    "\n",
    "X_tr = X_p[:t_len,:,:,:]\n",
    "Y_tr = Y_p[:t_len]\n",
    "\n",
    "X_te = X_p[t_len:t_len+v_len,:,:,:]\n",
    "Y_te = Y_p[t_len:t_len+v_len]\n",
    "\n",
    "X_v = X_p[t_len+v_len:,:,:,:]\n",
    "Y_v = Y_p[t_len+v_len:]\n",
    "\n",
    "classes = ['sem planta'.encode(), 'planta'.encode()]\n",
    "\n",
    "print(X_tr.shape, Y_tr.shape, X_te.shape, Y_te.shape, X_v.shape, Y_v.shape)\n",
    "\n",
    "# print(X_p.shape, Y_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = gen_list_of_image_names('/Users/henriquegoncalves/Documents/UFRJ/PF2/Images/imagens/dano','.jpg')\n",
    "ds = os.listdir('/Users/henriquegoncalves/Documents/UFRJ/PF2/Images/imagens/flange/')\n",
    "df = pd.DataFrame({'classe': ds})\n",
    "# df = pd.DataFrame({'dano': dano})\n",
    "df['video'] = df.apply(lambda row: row.classe[:18],axis=1)\n",
    "print(len(df))\n",
    "df.groupby(['video'],sort=False).count()\n",
    "\n",
    "# df['dano']\n",
    "# video_path = '/Users/henriquegoncalves/Documents/UFRJ/PF2/Videos/'\n",
    "# videos = [i for i in os.listdir(video_path) if i.endswith(\".mp4\")]\n",
    "# for video in videos:\n",
    "#     video = video.split('.')[0]\n",
    "# videos = [video.split('.')[0] for video in videos]\n",
    "\n",
    "# 06 teste, 07 valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df)-1411-1317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "543+537+597+600+648+666+645+585+519+27#+747+609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = gen_tergets(3)\n",
    "np.tile(targets[0],(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=3\n",
    "np.concatenate((np.ones((m,1)),np.zeros((m,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=3\n",
    "n = len(cl_names)\n",
    "targets = gen_tergets(n)\n",
    "np.concatenate(tuple([np.tile(targets[i],(m,1)) for i in range(n)]))\n",
    "# np.concatenate((np.tile(targets[0],(m,1)),np.tile(targets[1],(m,1)),np.tile(targets[2],(m,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(np.argmax(ygroup[index,:]))\n",
    "print(classes[int(ygroup[index,0])].decode())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(gen_targets(3)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
